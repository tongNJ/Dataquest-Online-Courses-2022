{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25bfc61",
   "metadata": {},
   "source": [
    "Over the last three lessons, we've managed to learn many new concepts, including conditional probability, independence, the law of total probability, and Bayes' theorem. In this lesson and the next, we'll look at an application of conditional probability — we'll build a spam filter.\n",
    "\n",
    "Spam is most commonly associated with emails. For instance, unwanted and unsolicited advertising emails are usually classified as spam. Spamming, however, occurs in ways and environments that don't necessarily relate to emails:\n",
    "\n",
    "- Articles or blog posts can be spammed with comments — the comments are ads or they are repetitive.\n",
    "\n",
    "- An educational forum may be spammed with posts that are, in fact, ads.\n",
    "\n",
    "- Mobile phone users may receive unwanted and unsolicited SMS messages, usually about advertising.\n",
    "\n",
    "In our lessons, we're going to build a spam filter specifically directed at preventing mobile phone spam. The filter will be able to analyze new messages and tell whether they are spam or not — this way, we might be able to prevent spam from bothering mobile phone users.\n",
    "\n",
    "To build the spam filter, we're going to use an algorithm called Naive Bayes — as the name suggests, the algorithm is based on Bayes' theorem.\n",
    "\n",
    "This lesson explores the theoretical side of the algorithm and is dedicated to helping you understand how the algorithm works. In the next lesson, which is a guided project, we'll apply the algorithm to a dataset of over 5,000 SMS messages.\n",
    "\n",
    "Let's start by getting an overview of the Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c58fdf",
   "metadata": {},
   "source": [
    "Imagine we just got a new SMS message:\n",
    "\n",
    "\"WINNER! You have 8 hours to claim your money by calling 090061701461. Claim code: KL341.\"\n",
    "This must be spam, but how could we create an algorithm that reaches the same conclusion? One thing we might think of is to create a list of words that occur frequently in spam messages, and then write a bunch of if statements:\n",
    "\n",
    "If the word \"money\" is in the message, then classify the message as spam.\n",
    "If the words \"secret\" and \"money\" are both in the message, then classify the message as spam; etc.\n",
    "However, as messages become numerous and more complex, coming up with the right if statements will slowly become very difficult.\n",
    "\n",
    "Another solution would be to classify a couple of messages ourselves and make the computer learn from our classification. And this is exactly what the Naive Bayes algorithm is about: It makes the computer learn from the classification a humans does, and then the computer uses that knowledge to classify new messages.\n",
    "\n",
    "The computer uses the specifications of the Naive Bayes algorithm to learn how we classify messages (what counts as spam and non-spam for us), and then it uses that human knowledge to estimate probabilities for new messages. Following the specifications of the algorithm, the computer tries to answer two conditional probability questions:\n",
    "\n",
    "- P(Spam|New message)= ?\n",
    "\n",
    "- P($Spam^C$|New message)= ?\n",
    "\n",
    "In plain English, these two questions are:\n",
    "\n",
    "What's the probability that this new message is spam, given its content (its words, punctuation, letter case, etc.)?\n",
    "What's the probability that this new message is non-spam, given its content?\n",
    "Once it has an answer to these two questions, the computer classifies the message as spam or non-spam based on the probability values. If the probability for spam is greater, then the message is classified as spam. Otherwise, it goes into the non-spam category.\n",
    "\n",
    "Now let's move to the next screen, where we'll start to look into the details of the algorithm.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a52ed",
   "metadata": {},
   "source": [
    "On the previous screen, we saw an overview of how the computer may classify new messages using the Naive Bayes algorithm:\n",
    "\n",
    "- The computer learns how humans classify messages.\n",
    "\n",
    "- Then it uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "\n",
    "- Finally, the computer classifies a new message based on the probability values it calculated in step 2 — if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may want a human to classify the message — we'll come back to this issue in the guided project).\n",
    "\n",
    "We saw on the previous screen that when a new message comes in, the algorithm requires the computer to calculate the following probabilities:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) =\\ ? \\\\\n",
    "P(Spam^C |New\\ message) =\\ ?\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Let's take the first equation and expand it using Bayes' theorem:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) = \\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Now let's do the same for the second equation:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam^C | New\\ message) = \\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "For the sake of example, let's assume the following probabilities are already known:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ message) = 0.4167 \\\\\n",
    "&P(New\\ Message | Spam) = 0.5 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "If the computer knows these values, then it can calculate the probabilities it needs to classify a new message:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) = \\frac{0.5 \\cdot 0.5}{0.4167} = 0.6 \\\\\n",
    "P(Spam^C | New\\ message) = \\frac{0.5 \\cdot 0.3334}{0.4167} = 0.4\n",
    "\\end{equation}\n",
    "\n",
    "Since \\begin{equation} P(Spam | New\\ message) > P(Spam^C | New\\ message)\\end{equation}, the computer will classify the new message as spam.\n",
    "\n",
    "Let's now do a quick exercise and continue the discussion in the next screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ea15b",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "A new mobile message has been received: \"URGENT!! You have one day left to claim your $873 prize.\" The following probabilities are known:\n",
    "\n",
    "\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ message) = 0.5417 \\\\\n",
    "&P(New\\ Message | Spam) = 0.75 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}\n",
    "\n",
    "Classify this new message as spam or non-spam:\n",
    "\n",
    "1. Calculate P(Spam|New Message). Assign your answer to p_spam_given_new_message.\n",
    "\n",
    "2. Calculate P($Spam^C$|New Message). Assign your answer to p_non_spam_given_new_message.\n",
    "\n",
    "3. Classify the message by comparing the probability values. If the message is spam, then assign the string 'spam' to the variable classification. Otherwise, assign the string 'non-spam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e170d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = 0.5\n",
    "p_non_spam = 0.5\n",
    "p_new_message = 0.5417\n",
    "p_new_message_given_spam = 0.75\n",
    "p_new_message_given_non_spam = 0.3334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05086d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|New Message) = 0.6922650913789921\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate P(Spam|New Message). Assign your answer to p_spam_given_new_message.\n",
    "\n",
    "p_spam_given_new_message = (p_spam * p_new_message_given_spam)/p_new_message\n",
    "\n",
    "print(f'P(Spam|New Message) = {p_spam_given_new_message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b49185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(SpamC|New Message) = 0.30773490862100794\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate P(SpamC|New Message). Assign your answer to p__not_spam_given_new_message.\n",
    "p_not_spam_given_new_message = (p_non_spam * p_new_message_given_non_spam)/p_new_message\n",
    "\n",
    "print(f'P(SpamC|New Message) = {p_not_spam_given_new_message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bd2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Classify the message by comparing the probability values. If the message is spam, then assign the string 'spam' to the variable classification. \n",
    "# Otherwise, assign the string 'non-spam'.\n",
    "classification = 'spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca2b253",
   "metadata": {},
   "source": [
    "On the last screen, we saw the computer can use these two equations to calculate the probabilities it needs to classify new messages:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) = \\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)} \\\\\n",
    "P(Spam^C | New\\ message) = \\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Although we've taken a great first step so far, the actual equations of the Naive Bayes algorithm are a bit different — we'll gradually develop the equations throughout this lesson. Let's start by pointing out that both equations above have the same denominator: P(New message).\n",
    "\n",
    "When a new message comes in, P(New message) has the same value for both equations. Since we only need to compare the results of the two equations to classify a new message, we can ignore the division:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)}\\ \\ \\ \\  \\xrightarrow[]{becomes}\\ \\ \\ \\  P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "\\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\\ \\ \\  \\xrightarrow[]{becomes}\\ \\ \\ \\  P(Spam^C) \\cdot P(New\\ Message | Spam^C)\n",
    "\\end{equation}\n",
    "\n",
    "This means our two equations reduce to:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) = P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "P(Spam^C | New\\ message) = P(Spam^C) \\cdot P(New\\ Message | Spam^C)\n",
    "\\end{equation}\n",
    "\n",
    "Ignoring the division doesn't affect the algorithm's ability to classify new messages. For instance, let's repeat the classification we did on the previous screen using the new equations above. Recall that we assumed we already know these values:\n",
    "\n",
    "\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ message) = 0.4167 \\\\\n",
    "&P(New\\ Message | Spam) = 0.5 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}\n",
    "\n",
    "Previously, the algorithm classified the new message as spam. Using the new equations, we see the conclusion is identical — the new message is spam because \n",
    "\n",
    "P(Spam | New\\ message) > P(Spam^C | New\\ message)\n",
    "\n",
    "\\begin{aligned}\n",
    "P(Spam | New\\ message) &= P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "&= 0.5 \\cdot 0.5 = 0.25\n",
    "\\end{aligned}\n",
    "\n",
    "\\begin{aligned}\n",
    "P(Spam^C | New\\ message) &= P(Spam^C) \\cdot P(New\\ Message | Spam^C) \\\\\n",
    "&= 0.5 \\cdot 0.3334 = 0.1667\n",
    "\\end{aligned}\n",
    "\n",
    "The classification works fine, but ignoring the division changes the probability values, and some probability rules also begin to break. \n",
    "\n",
    "ven though probability rules break, the Naive Bayes algorithm still requires us to ignore the division by P(New message). This might not make a lot of sense, but there's actually a very good reason we do that.\n",
    "\n",
    "The main goal of the algorithm is to classify new messages, not to calculate probabilities — calculating probabilities is just a means to an end. Ignoring the division by P(New message) means less calculations, which can make a lot of difference when we use the algorithm to classify 500,000 new messages.\n",
    "\n",
    "It's true the probability values are not accurate anymore. However, this is not important with respect to the the goal of the algorithm — correctly classifying new messages (not to accurately estimate probabilities).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b90b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
