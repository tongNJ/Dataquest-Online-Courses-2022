{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f60f94",
   "metadata": {},
   "source": [
    "Over the last three lessons, we've managed to learn many new concepts, including conditional probability, independence, the law of total probability, and Bayes' theorem. In this lesson and the next, we'll look at an application of conditional probability — we'll build a spam filter.\n",
    "\n",
    "Spam is most commonly associated with emails. For instance, unwanted and unsolicited advertising emails are usually classified as spam. Spamming, however, occurs in ways and environments that don't necessarily relate to emails:\n",
    "\n",
    "- Articles or blog posts can be spammed with comments — the comments are ads or they are repetitive.\n",
    "\n",
    "- An educational forum may be spammed with posts that are, in fact, ads.\n",
    "\n",
    "- Mobile phone users may receive unwanted and unsolicited SMS messages, usually about advertising.\n",
    "\n",
    "In our lessons, we're going to build a spam filter specifically directed at preventing mobile phone spam. The filter will be able to analyze new messages and tell whether they are spam or not — this way, we might be able to prevent spam from bothering mobile phone users.\n",
    "\n",
    "To build the spam filter, we're going to use an algorithm called Naive Bayes — as the name suggests, the algorithm is based on Bayes' theorem.\n",
    "\n",
    "This lesson explores the theoretical side of the algorithm and is dedicated to helping you understand how the algorithm works. In the next lesson, which is a guided project, we'll apply the algorithm to a dataset of over 5,000 SMS messages.\n",
    "\n",
    "Let's start by getting an overview of the Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf14c7e",
   "metadata": {},
   "source": [
    "Imagine we just got a new SMS message:\n",
    "\n",
    "\"WINNER! You have 8 hours to claim your money by calling 090061701461. Claim code: KL341.\"\n",
    "This must be spam, but how could we create an algorithm that reaches the same conclusion? One thing we might think of is to create a list of words that occur frequently in spam messages, and then write a bunch of if statements:\n",
    "\n",
    "If the word \"money\" is in the message, then classify the message as spam.\n",
    "If the words \"secret\" and \"money\" are both in the message, then classify the message as spam; etc.\n",
    "However, as messages become numerous and more complex, coming up with the right if statements will slowly become very difficult.\n",
    "\n",
    "Another solution would be to classify a couple of messages ourselves and make the computer learn from our classification. And this is exactly what the Naive Bayes algorithm is about: It makes the computer learn from the classification a humans does, and then the computer uses that knowledge to classify new messages.\n",
    "\n",
    "The computer uses the specifications of the Naive Bayes algorithm to learn how we classify messages (what counts as spam and non-spam for us), and then it uses that human knowledge to estimate probabilities for new messages. Following the specifications of the algorithm, the computer tries to answer two conditional probability questions:\n",
    "\n",
    "- P(Spam|New message)= ?\n",
    "\n",
    "- P($Spam^C$|New message)= ?\n",
    "\n",
    "In plain English, these two questions are:\n",
    "\n",
    "What's the probability that this new message is spam, given its content (its words, punctuation, letter case, etc.)?\n",
    "What's the probability that this new message is non-spam, given its content?\n",
    "Once it has an answer to these two questions, the computer classifies the message as spam or non-spam based on the probability values. If the probability for spam is greater, then the message is classified as spam. Otherwise, it goes into the non-spam category.\n",
    "\n",
    "Now let's move to the next screen, where we'll start to look into the details of the algorithm.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8676e1b",
   "metadata": {},
   "source": [
    "On the previous screen, we saw an overview of how the computer may classify new messages using the Naive Bayes algorithm:\n",
    "\n",
    "- The computer learns how humans classify messages.\n",
    "\n",
    "- Then it uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "\n",
    "- Finally, the computer classifies a new message based on the probability values it calculated in step 2 — if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may want a human to classify the message — we'll come back to this issue in the guided project).\n",
    "\n",
    "We saw on the previous screen that when a new message comes in, the algorithm requires the computer to calculate the following probabilities:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) =\\ ? \\\\\n",
    "P(Spam^C |New\\ message) =\\ ?\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Let's take the first equation and expand it using Bayes' theorem:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) = \\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Now let's do the same for the second equation:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam^C | New\\ message) = \\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "For the sake of example, let's assume the following probabilities are already known:\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ message) = 0.4167 \\\\\n",
    "&P(New\\ Message | Spam) = 0.5 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "If the computer knows these values, then it can calculate the probabilities it needs to classify a new message:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) = \\frac{0.5 \\cdot 0.5}{0.4167} = 0.6 \\\\\n",
    "P(Spam^C | New\\ message) = \\frac{0.5 \\cdot 0.3334}{0.4167} = 0.4\n",
    "\\end{equation}\n",
    "\n",
    "Since \\begin{equation} P(Spam | New\\ message) > P(Spam^C | New\\ message)\\end{equation}, the computer will classify the new message as spam.\n",
    "\n",
    "Let's now do a quick exercise and continue the discussion in the next screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c108c0",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "A new mobile message has been received: \"URGENT!! You have one day left to claim your $873 prize.\" The following probabilities are known:\n",
    "\n",
    "\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ message) = 0.5417 \\\\\n",
    "&P(New\\ Message | Spam) = 0.75 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}\n",
    "\n",
    "Classify this new message as spam or non-spam:\n",
    "\n",
    "1. Calculate P(Spam|New Message). Assign your answer to p_spam_given_new_message.\n",
    "\n",
    "2. Calculate P($Spam^C$|New Message). Assign your answer to p_non_spam_given_new_message.\n",
    "\n",
    "3. Classify the message by comparing the probability values. If the message is spam, then assign the string 'spam' to the variable classification. Otherwise, assign the string 'non-spam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652fddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = 0.5\n",
    "p_non_spam = 0.5\n",
    "p_new_message = 0.5417\n",
    "p_new_message_given_spam = 0.75\n",
    "p_new_message_given_non_spam = 0.3334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60a3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|New Message) = 0.6922650913789921\n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate P(Spam|New Message). Assign your answer to p_spam_given_new_message.\n",
    "\n",
    "p_spam_given_new_message = (p_spam * p_new_message_given_spam)/p_new_message\n",
    "\n",
    "print(f'P(Spam|New Message) = {p_spam_given_new_message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8195c645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(SpamC|New Message) = 0.30773490862100794\n"
     ]
    }
   ],
   "source": [
    "# 2. Calculate P(SpamC|New Message). Assign your answer to p__not_spam_given_new_message.\n",
    "p_not_spam_given_new_message = (p_non_spam * p_new_message_given_non_spam)/p_new_message\n",
    "\n",
    "print(f'P(SpamC|New Message) = {p_not_spam_given_new_message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf152e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Classify the message by comparing the probability values. If the message is spam, then assign the string 'spam' to the variable classification. \n",
    "# Otherwise, assign the string 'non-spam'.\n",
    "classification = 'spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6f1c1",
   "metadata": {},
   "source": [
    "On the last screen, we saw the computer can use these two equations to calculate the probabilities it needs to classify new messages:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) = \\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)} \\\\\n",
    "P(Spam^C | New\\ message) = \\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Although we've taken a great first step so far, the actual equations of the Naive Bayes algorithm are a bit different — we'll gradually develop the equations throughout this lesson. Let's start by pointing out that both equations above have the same denominator: P(New message).\n",
    "\n",
    "When a new message comes in, P(New message) has the same value for both equations. Since we only need to compare the results of the two equations to classify a new message, we can ignore the division:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{P(Spam) \\cdot P(New\\ Message | Spam)}{P(New\\ message)}\\ \\ \\ \\  \\xrightarrow[]{becomes}\\ \\ \\ \\  P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "\\frac{P(Spam^C) \\cdot P(New\\ Message | Spam^C)}{P(New\\ message)}\\ \\ \\  \\xrightarrow[]{becomes}\\ \\ \\ \\  P(Spam^C) \\cdot P(New\\ Message | Spam^C)\n",
    "\\end{equation}\n",
    "\n",
    "This means our two equations reduce to:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) = P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "P(Spam^C | New\\ message) = P(Spam^C) \\cdot P(New\\ Message | Spam^C)\n",
    "\\end{equation}\n",
    "\n",
    "Ignoring the division doesn't affect the algorithm's ability to classify new messages. For instance, let's repeat the classification we did on the previous screen using the new equations above. Recall that we assumed we already know these values:\n",
    "\n",
    "\\begin{aligned}\n",
    "&P(Spam) = 0.5 \\\\\n",
    "&P(Spam^C) = 0.5 \\\\\n",
    "&P(New\\ message) = 0.4167 \\\\\n",
    "&P(New\\ Message | Spam) = 0.5 \\\\\n",
    "&P(New\\ Message | Spam^C) = 0.3334\n",
    "\\end{aligned}\n",
    "\n",
    "Previously, the algorithm classified the new message as spam. Using the new equations, we see the conclusion is identical — the new message is spam because \n",
    "\n",
    "P(Spam | New\\ message) > P(Spam^C | New\\ message)\n",
    "\n",
    "\\begin{aligned}\n",
    "P(Spam | New\\ message) &= P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "&= 0.5 \\cdot 0.5 = 0.25\n",
    "\\end{aligned}\n",
    "\n",
    "\\begin{aligned}\n",
    "P(Spam^C | New\\ message) &= P(Spam^C) \\cdot P(New\\ Message | Spam^C) \\\\\n",
    "&= 0.5 \\cdot 0.3334 = 0.1667\n",
    "\\end{aligned}\n",
    "\n",
    "The classification works fine, but ignoring the division changes the probability values, and some probability rules also begin to break. \n",
    "\n",
    "ven though probability rules break, the Naive Bayes algorithm still requires us to ignore the division by P(New message). This might not make a lot of sense, but there's actually a very good reason we do that.\n",
    "\n",
    "The main goal of the algorithm is to classify new messages, not to calculate probabilities — calculating probabilities is just a means to an end. Ignoring the division by P(New message) means less calculations, which can make a lot of difference when we use the algorithm to classify 500,000 new messages.\n",
    "\n",
    "It's true the probability values are not accurate anymore. However, this is not important with respect to the the goal of the algorithm — correctly classifying new messages (not to accurately estimate probabilities).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e962e5",
   "metadata": {},
   "source": [
    "On the previous screen, we optimized the algorithm and concluded that we can use these two optimized equations if all we're interested in is classifying messages (and not calculating accurate probabilities):\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | New\\ message) \\propto P(Spam) \\cdot P(New\\ Message | Spam) \\\\\n",
    "P(Spam^C | New\\ message) \\propto P(Spam^C) \\cdot P(New\\ Message | Spam^C)\n",
    "\\end{equation}\n",
    "\n",
    "We'll now look at how the algorithm can use messages that are already classified by humans to calculate the values it needs for:\n",
    "\n",
    "P(Spam) and P($Spam^C$)\n",
    "\n",
    "P(New message|Spam) and P(New message|$Spam^C$).\n",
    "\n",
    "\n",
    "We'll start with some examples that may look a bit too simplistic and unrealistic, but they will make it easier to understand the mathematics behind the algorithm.\n",
    "\n",
    "Let's say we have three messages that are already classified:\n",
    "\n",
    "![probability-pic-24](https://raw.githubusercontent.com/tongNJ/Dataquest-Online-Courses-2022/main/Pictures/probability-pic-24.png)\n",
    "\n",
    "Now let's say the one-word message \"secret\" comes in and we want to use the Naive Bayes algorithm to classify it — to tell whether it's spam or non-spam.\n",
    "\n",
    "![probability-pic-25](https://raw.githubusercontent.com/tongNJ/Dataquest-Online-Courses-2022/main/Pictures/probability-pic-25.png)\n",
    "\n",
    "As we learned, we first need to answer these two probability questions (note that we changed New Message to \"secret\" inside the notation below) and then compare the values (recall that the ∝ symbol replaces the equal sign):\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | \\text{\"secret\"}) \\propto P(Spam) \\cdot P(\\text{\"secret\"} | Spam) \\\\\n",
    "P(Spam^C | \\text{\"secret\"}) \\propto P(Spam^C) \\cdot P(\\text{\"secret\"} | Spam^C)\n",
    "\\end{equation}\n",
    "\n",
    "Let's begin with the first equation, for which we need to find the values of P(Spam) and P(\"secret\"|Spam). To find P(Spam), we use the messages that are already classified and divide the number of spam messages by the total number of messages:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam) = \\frac{\\text{number of spam messages}}{\\text{total number of messages}} = \\frac{2}{3}\n",
    "\\end{equation}\n",
    "\n",
    "To calculate P(\"secret\"|Spam), we only look at the spam messages and divide the number of times the word \"secret\" occurred in all the spam messages by the total number of words.\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\text{\"secret\"}| Spam) = \\frac{\\text{number of times the word \"secret\" occurs}}{\\text{total number of words in all spam messages}}\n",
    "\\end{equation}\n",
    "\n",
    "Notice that \"secret\" occurs four times in the spam messages:\n",
    "\n",
    "![probability-pic-26](https://raw.githubusercontent.com/tongNJ/Dataquest-Online-Courses-2022/main/Pictures/probability-pic-26.png)\n",
    "\n",
    "We have two spam messages and there's a total of seven words in all of them, so P(\"secret\"|Spam) is:\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\text{\"secret\"}| Spam) = \\frac{\\text{number of times the word \"secret\" occurs}}{\\text{total number of words in all spam messages}} = \\frac{4}{7}\n",
    "\\end{equation}\n",
    "\n",
    "Now that we know the values for P(Spam) and P(\"secret\"|Spam), we have all we need to calculate P(Spam|\"secret\"):\n",
    "\n",
    "\\begin{aligned}\n",
    "P(Spam | \\text{\"secret\"}) &\\propto P(Spam) \\cdot P(\\text{\"secret\"} | Spam) \\\\\n",
    "&= \\frac{2}{3} \\cdot \\frac{4}{7} = \\frac{8}{21}\n",
    "\\end{aligned}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b4a7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "p_spam_given_secret = 8/21\n",
    "p_non_spam = 1/3\n",
    "p_secret_given_non_spam = 1/4\n",
    "\n",
    "p_non_spam_given_secret = p_non_spam*p_secret_given_non_spam\n",
    "\n",
    "if p_non_spam_given_secret > p_spam_given_secret:\n",
    "    classification='non-spam'\n",
    "else:\n",
    "    classification='spam'\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51030e8a",
   "metadata": {},
   "source": [
    "On the previous screen, we used our algorithm to classify the message \"secret\", and we concluded it's spam. The message \"secret\" has only one word, but what about the situation where we have to classify messages that have more words?\n",
    "\n",
    "Let's say we want to classify the message \"secret place secret secret\" based on four messages that are already classified (the four messages below are different than what what we saw on the previous screen):\n",
    "\n",
    "\n",
    "![probability-pic-27](https://raw.githubusercontent.com/tongNJ/Dataquest-Online-Courses-2022/main/Pictures/probability-pic-27.png)\n",
    "\n",
    "To calculate the probabilities we need, we'll treat each word in our new message separately. This means that the word \"secret\" at the beginning is different and separate from the word \"secret\" at the end. There are four words in the message \"secret place secret secret\", and we're going to abbreviate them \"w1\", \"w2\", \"w3\" and \"w4\" (the \"w\" comes from \"word\").\n",
    "\n",
    "![probability-pic-28](https://raw.githubusercontent.com/tongNJ/Dataquest-Online-Courses-2022/main/Pictures/probability-pic-28.png)\n",
    "\n",
    "Since we treat each word separately, these are the two equations we can use to calculate the probabilities:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2,w_3,w_4) \\propto P(Spam) \\cdot P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot P(w_3|Spam) \\cdot P(w_4|Spam) \\\\\n",
    "P(Spam^C | w_1,w_2,w_3,w_4) \\propto P(Spam^C) \\cdot P(w_1|Spam^C) \\cdot P(w_2|Spam^C) \\cdot P(w_3|Spam^C) \\cdot P(w_4|Spam^C) \\\\\n",
    "\\end{equation}\n",
    "\n",
    "(On the next screen, we'll explain in detail why we're using these equations specifically.)\n",
    "\n",
    "Let's begin with calculating P(Spam|w1, w2, w3, w4). To calculate the probabilities we need, we'll look at the four messages that are already classified. We have four messages and two of them are spam, so:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam) = \\frac{2}{4} = \\frac{1}{2}\n",
    "\\end{equation}\n",
    "\n",
    "The first word, w1, is \"secret\", and we see that \"secret\" occurs four times in all spam messages. There's a total of seven words in all the spam messages, so:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_1|Spam) = \\frac{4}{7} \n",
    "\\end{equation}\n",
    "\n",
    "Applying a similar reasoning, we have:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_2|Spam) = \\frac{1}{7} \\\\\n",
    "P(w_3|Spam) = \\frac{4}{7} \\\\\n",
    "P(w_4|Spam) = \\frac{4}{7}\n",
    "\\end{equation}\n",
    "\n",
    "We now have all the probabilities we need to calculate P(Spam|w1, w2, w3, w4):\n",
    "\n",
    "\\begin{aligned}\n",
    "P(Spam | w_1,w_2,w_3,w_4) &\\propto P(Spam) \\cdot P(w_1|Spam) \\cdot P(w_2|Spam) \\cdot P(w_3|Spam) \\cdot P(w_4|Spam) \\\\\n",
    "&= \\frac{1}{2} \\cdot \\frac{4}{7} \\cdot \\frac{1}{7} \\cdot \\frac{4}{7} \\cdot \\frac{4}{7} = \\frac{64}{4802} = 0.01333\n",
    "\\end{aligned}\n",
    "\n",
    "Let's now take similar steps to calculate P(SpamC|w1, w2, w3, w4), and then classify the message \"secret place secret secret\" as spam or non-spam.\n",
    "\n",
    "Using the table below (the same as above), classify the message \"secret place secret secret\" as spam or non-spam.\n",
    "\n",
    "![probability-pic-29](https://raw.githubusercontent.com/tongNJ/Dataquest-Online-Courses-2022/main/Pictures/probability-pic-29.png)\n",
    "\n",
    "1. Calculate P(SpamC|w1, w2, w3, w4). Assign the answer to p_non_spam_given_w1_w2_w3_w4. Check the hint if you get stuck.\n",
    "\n",
    "\n",
    "2. Compare P(SpamC|w1, w2, w3, w4) with P(Spam|w1, w2, w3, w4) and classify the message \"secret place secret secret\" — if the message is spam, then assign the string 'spam' to the variable classification. Otherwise, assign the string 'non-spam'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61525a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(SpamC|w1, w2, w3, w4) = 0.0006096631611034902\n",
      "P(Spam|w1, w2, w3, w4) = 0.013327780091628489\n",
      "The message is spam\n"
     ]
    }
   ],
   "source": [
    "p_spam_given_w1_w2_w3_w4 = 64/4802\n",
    "\n",
    "p_non_spam = 2/4\n",
    "p_w1_given_non_spam = 2/9\n",
    "p_w2_given_non_spam = 1/9\n",
    "p_w3_given_non_spam = 2/9\n",
    "p_w4_given_non_spam = 2/9\n",
    "\n",
    "p_non_spam_given_w1_w2_w3_w4 = p_non_spam*p_w1_given_non_spam*p_w2_given_non_spam*p_w3_given_non_spam*p_w4_given_non_spam\n",
    "\n",
    "if p_spam_given_w1_w2_w3_w4>p_non_spam_given_w1_w2_w3_w4:\n",
    "    classification='spam'\n",
    "else:\n",
    "    classification='non-spam'\n",
    "    \n",
    "print(f'P(SpamC|w1, w2, w3, w4) = {p_non_spam_given_w1_w2_w3_w4}')\n",
    "print(f'P(Spam|w1, w2, w3, w4) = {p_spam_given_w1_w2_w3_w4}')\n",
    "print(f'The message is {classification}')\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b6094",
   "metadata": {},
   "source": [
    "On a previous screen, we looked at a few messages that were already classified:\n",
    "\n",
    "![probability-pic-30](https://raw.githubusercontent.com/tongNJ/Dataquest-Online-Courses-2022/main/Pictures/probability-pic-30.png)\n",
    "\n",
    "Above, we have four messages and nine unique words: \"secret\", \"party\", \"at\", \"my\", \"place\", \"money\", \"you\", \"know\", \"the\". We call the set of unique words a vocabulary.\n",
    "\n",
    "Now, what if we receive a new message that contains words which are not part of the **vocabulary**? How do we calculate probabilities for these kind of words?\n",
    "\n",
    "For instance, say we received the message \"secret code to unlock the money\".\n",
    "\n",
    "![probability-pic-31](https://raw.githubusercontent.com/tongNJ/Dataquest-Online-Courses-2022/main/Pictures/probability-pic-31.png)\n",
    "\n",
    "Notice that for this new message:\n",
    "\n",
    "- The words \"code\", \"to\", and \"unlock\" are not part of the vocabulary.\n",
    "\n",
    "- The word \"secret\" is part of both spam and non-spam messages.\n",
    "\n",
    "- The word \"money\" is only part of the spam messages and is missing from the non-spam messages.\n",
    "\n",
    "- The word \"the\" is missing from the spam messages and is only part of the non-spam messages.\n",
    "\n",
    "**Whenever we have to deal with words that are not part of the vocabulary, one solution is to ignore them when we're calculating probabilities. If we wanted to calculate P(Spam|\"secret code to unlock the money\"), we could skip calculating P(\"code\"|Spam), P(\"to\"|Spam), and P(\"unlock\"|Spam) because \"code\", \"to\", and \"unlock\" are not part of the vocabulary:**\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam|\\text{\"secret code to unlock the money\"}) \\propto P(Spam) \\cdot {P(\\text{\"secret\"}|Spam) \\cdot P(\\text{\"the\"}|Spam) \\cdot P(\\text{\"money\"}|Spam)}\n",
    "\\end{equation}\n",
    "\n",
    "We can also apply the same reasoning for calculating P(SpamC|\"secret code to unlock the money\"):\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam^C|\\text{\"secret code to unlock the money\"}) \\propto P(Spam^C) \\cdot P(\\text{\"secret\"}|Spam^C) \\cdot P(\\text{\"the\"}|Spam^C) \\cdot P(\\text{\"money\"}|Spam^C)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a765d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "p_spam = 2/4\n",
    "p_secret_given_spam = 4/7\n",
    "p_the_given_spam = 0/7\n",
    "p_money_given_spam = 2/7\n",
    "p_spam_given_message = (p_spam * p_secret_given_spam * p_the_given_spam*\n",
    "                         p_money_given_spam)\n",
    "\n",
    "p_non_spam = 2/4\n",
    "p_secret_given_non_spam = 2/9\n",
    "p_the_given_non_spam = 1/9\n",
    "p_money_given_non_spam = 0\n",
    "p_non_spam_given_message=p_non_spam*p_secret_given_non_spam*p_the_given_non_spam*p_money_given_non_spam\n",
    "\n",
    "print(p_spam_given_message)\n",
    "print(p_non_spam_given_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de99d2",
   "metadata": {},
   "source": [
    "In the previous exercise, we saw that both P(Spam|\"secret code to unlock the money\") and P(SpamC|\"secret code to unlock the money\") were equal to 0. This will always happen when we have words that occur in only one category — \"money\" occurs only in spam messages, while \"the\" only occurs in non-spam messages.\n",
    "\n",
    "When we calculate P(Spam|\"secret code to unlock the money\"), we can see that P(\"the\"|Spam) is equal to 0 because \"the\" is not part of the spam messages. Unfortunately, that single value of 0 has the drawback of turning the result of the entire equation to 0:\n",
    "\n",
    "\\begin{aligned}\n",
    "P(Spam|\\text{\"secret code to unlock the money\"}) &\\propto P(Spam) \\cdot P(\\text{\"secret\"}|Spam) \\cdot P(\\text{\"the\"}|Spam) \\cdot P(\\text{\"money\"}|Spam) \\\\\n",
    "&= \\frac{2}{4} \\cdot \\frac{4}{7} \\cdot \\frac{0}{7} \\cdot \\frac{2}{7} = 0\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "To fix the problem, we're going to use a technique called additive smoothing, where we add a smoothing parameter \n",
    "α. In the equation below, we'll use α=1 (below, NVocabulary represents the number of unique words in all the messages — both spam and non-spam).\n",
    "\n",
    "Words like \"the\" are thus given special treatment and their probability are increased artificially to avoid non-zero cases, while words like \"secret\" are treated normally. To keep the probability values proportional across all words, we're going to use the additive smoothing for every word:\n",
    "\n",
    "## Very important formula\n",
    "\\begin{equation}\n",
    "P(\\text{\"the\"}|Spam) = \\frac{N_{\\text{\"the\"}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(\\text{\"secret\"}|Spam) = \\frac{N_{\\text{\"secret\"}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "### --------------------------------------\n",
    "\n",
    "As a side note, when **α=1**, the additive smoothing technique is most commonly known as **Laplace smoothing** (or add-one smoothing). However, it is also possible to use **α<1**, in which case the technique is called **Lidstone smoothing**. If you want to learn more about additive smoothing, you can start here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f218f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd41fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b5182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c280e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d631f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3e2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea31a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4566d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
